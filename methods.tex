%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Methods}
\label{ch:Methods}
\TODO{Include some pretty figures of the photon distributions I get at each step of building the simulation}

The simulation of the ARICH detector was created using \textsc{ROOT}: an object-oriented scientific computing framework based off C++ and developed at CERN \cite{root}.
\textsc{ROOT} is used for its ease of use, the high degree of organization and extensibility that comes from its object-oriented nature, and its high efficiency when compiled.
The simulation was created in steps of increasing added complexity, which are outlined in this chapter.


\section{Initial Simulation}
\label{sec:experiment}
The first step in building the simulation was to generate a stream of charged particles, representing the charged pions and kaons and protons produced in an experiment.
If we define the $z$ axis to be the downstream direction, then the inputs to the simulation are:
\begin{itemize}
\item The $x$ and $y$ position of a particle as it enters the aerogel.
\item The error on the $x$ and $y$ position of the particle, corresponding to the position resolution of the upstream particle tracker.
\item The $x$ and $y$ components of the unit vector representing the direction of the particle.
\item The error on the $x$ and $y$ direction of the particle, corresponding to the direction resolution of the upstream particle tracker.
\item The velocity $\beta$ of the particle.
\end{itemize} 
The simulation generates 10,000 such particles whose positions and directions are randomly drawn from a Gaussian distribution with the specified mean values and errors. 

A slab of aerogel is defined as a 2 cm thick, 10 cm by 10 cm volume, with a refractive index of 1.035. 
For a given particle velocity $\beta$, we calculate the mean number of photons per unit length generated by a charged particle passing through with equation \ref{eq:photonNumber}. For each particle, we 

For each generated particle, we generate a number of photons equal to the result of equation \ref{eq:photonNumber} multiplied by the distance the particle has to travel through the aerogel.
The initial position of these photons are randomly distributed along the path travelled by the particle.
Their polar angle $\theta$ with respect to the direction of travel of the particle is given by equation \ref{eq:cherenkovAngle}, and their azimuthal angle is randomly drawn from between 0 and $2\pi$. Given 
If we are given the direction vector of the particle, we can use a rotation matrix to get the resulting direction vectors for each of the photons it generates.
This is given by \TODO{Include here Rodrigue's rotation formula, and how it is adapted into matrix form}.

The photons ultimately are detected by an array of PMTs, which have a known quantum efficiency, characterized over a range of frequencies of light.
The efficiency curve of the PMTs is plotted in \TODO{cite datasheet?} Figure \TODO{INCLUDE QUANTUM EFF GRAPH}, and is given over a range from 267 to 687 nm.
From equation \ref{eq:frankTamm}, we see that the distribution of photon wavelengths follows the distribution $\frac{1}{\lambda^2}$, so each photon is produced with a wavelength randomly drawn from this distribution on a range from 250 nm to 695 nm.
These values were chosen, because if we linearly extrapolate the quantum efficiency curve, we see that we do not expect to get any detector response for photons of wavelengths outside of this range.
Because all optical processes included in this simulation are inelastic, we do not expect any photon wavelength to change between the point of generation and the point of detection.
Therefore, after generating Cherenkov photons we may randomly reject them immediately based on their probability of being detected, and not simulate their paths any further.

The PMTs have dimensions of 48.5 mm $\times$ 48.5 mm.
Each PMT contains $8 \times 8$ pixels, and have a packing density of 87\%. 
The PMTs are expected to be arranged onto a 30 cm $\times$ 30 cm plane with a packing efficiency of $80\%$, 20 cm downstream of the first layer of aerogel.
\TODO{Find out where packing efficiency of 0.8 comes from}.
To model the photon detector array, we simply project the photons downstream onto a 30 cm $\times$ 30 cm histogram with $48 \times 48$ bins.
The number of photons counted in each bin is scaled by a factor of $80\% \times 87\%$ to account for the packing efficiencies.


\section{Optical Effects}
Following this initial simulation, more sophisticated optical effects were added in.

\TODO{give credit to Tabata?} Several aerogel slabs have been fabricated for EMPHATIC: they are 2 cm in thickness, 

$d1*tan(acos(1.0/n1)) = d2*tan(acos(1.0/n2)) $

As described in Section \ref{sec:optics}, the primary optical effect to account for is Rayleigh Scattering, wherein photons scatter with a probability proportional to $\lambda^{-4}$, and in a direction proportional to $1 + \cos^2(\theta)$.
For each aerogel available for use in the experiment, the transmittance had been measured at different wavelengths of light.
For each wavelength, the Rayleigh scattering interaction length was approximated by the following formula:

$$
L(\lambda) = \frac{-d}{\log(T(\lambda))}
 $$
 In this equation, $T(\lambda)$ is the transmittance of light at a wavelength $\lambda$, $d$ is the thickness of the aerogel, and $L$ is the estimated mean interaction length of a photon before undergoing Rayleigh scattering.

\TODO{Here I will: \\
- go more in-depth of how I efficiently determine at what step a photon will scatter \\
- talk about multiple-scattering \\
- talk about refraction
}

An example of a photon distribution is shown in Figure \ref{fig:photonHist}.

\begin{figure}[]
\centering
\resizebox{0.9\textwidth}{!}{\includegraphics{./figs/photonHist.pdf}}
\caption[Example of simulated photon distribution for centered 7.0 GeV pion beam]{Histograms displaying the simulated photon distribution for a 7.0 GeV pion beam travelling directly along the $z$-axis. Clockwise, from bottom left: (1) histogram of mean detected photon count per pixel on detector plane, (2) $y$-axis projection of photon distribution, (3) histogram of photon detections as function of distance from origin, (4) $x$-axis projection of photon distribution. }
\label{fig:photonHist} 
\end{figure}

\section{Particle Identification}
\label{sec:particleIdentification}
In order to identify particles using the \ac{ARICH} detector, a particle likelihood method is used \cite{richImpact, belleArich}.
For this method, we take the measured momentum of the particle, and use Equation \TODO{Include relativistic equation for mass / momentum / velocity here } to determine the expected velocity for different candidate particles masses.
The candidate particles of interest to the experiment are protons, electrons, pions, and kaons.
For each velocity hypothesis, we run 10,000 simulations of particles moving at that velocity, with the same measured initial trajectory as input, and get the distribution of the resulting photons.
For each pixel of the detector, this procedure will give a value $\lambda_i(\beta)$, equal to the expected number of photons striking pixel $i$ in the detector due to a particle of velocity $\beta$. 

For a given experimental event, we will detect $N_i$ photons in each pixel $i$.
In reality, the PMTs are only capable of registering whether or not a photon has been detected - if multiple photons strike a single pixel in a very short amount of time, it will not be able to distinguish the number detected, so we just know if $N_i = 0$ or $N_i > 0$.

The probability that zero photons strike pixel $i$ is given by the Poisson distribution for zero events:
$$ P_i(N_i=0; \beta) = e^{-\lambda_i(\beta)} $$
 The probability that one or more photons strike pixel $i$ must then be:
$$ P_i(N_i>1; \beta) = 1 - e^{-\lambda_i(\beta)} $$

By multiplying the probabilities of getting the observed result in each pixel $i$ of the detector, we calculate the likelihood for that value of $\beta$:

$$L_\beta = \prod_{i}P_i(N_i; \beta)$$

For convenience, we actually compute:
\begin{equation}
    \label{eq:loglikelihood}
    -2\ln(L_\beta) = -2\sum_i \ln(P_i(N_i; \beta))
\end{equation}

We compute the log-likelihood of our data matching each of particle hypothesis, and choose that which minimizes the value.

\TODO{Due to the relatively high error associated with the measurement of the particle momenta, if I find that this method is not entirely sufficient at identifying particles then I will enhance the technique by scanning over different momentum hypotheses. This has not yet been implemented}

\section{Multi-particle events}
\TODO{In this section, I will  talk about multi-particle events. It is often the case that the photons from several different particles will be detected at the same time. The resulting photon distributions cannot necessarily be disentangled, so I will have to look at how to fit both particles at once. This has not yet been implemented.}


\endinput

Any text after an \endinput is ignored.
You could put scraps here or things in progress.
